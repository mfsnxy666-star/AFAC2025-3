import pandas as pd
import json
import re
import time
from typing import List, Dict, Tuple
import openpyxl
from openpyxl import Workbook
import os
from datetime import datetime
import pandas as pd
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class DeepSeekAPIProcessor:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
    
    def call_deepseek_chat_for_analysis(self, question: str, answer: str) -> str:
        """è°ƒç”¨DeepSeek-Chatè¡¥å……è§£é¢˜è¿‡ç¨‹"""
        prompt = f"""
{question}

è¯¥é¢˜ç›®çš„æ­£ç¡®ç­”æ¡ˆï¼š{answer}

æ ¹æ®å·²çŸ¥çš„ç­”æ¡ˆï¼Œå¯¹åŸé—®é¢˜ä»¥åŠé—®é¢˜å¯¹åº”çš„å››ä¸ªé€‰é¡¹è¿›è¡Œåˆ†æï¼š

é—®é¢˜åˆ†æï¼š
[åˆ†æé¢˜ç›®çš„å…³é”®ä¿¡æ¯ã€æ¶‰åŠçš„çŸ¥è¯†ç‚¹ã€è§£é¢˜æ€è·¯ç­‰ï¼Œä¸å¾—è¶…è¿‡150å­—]

é€‰é¡¹åˆ†æï¼š
[å¦‚æœæ˜¯é€‰æ‹©é¢˜ï¼Œåˆ†æå„ä¸ªé€‰é¡¹çš„æ­£ç¡®æ€§ï¼›å¦‚æœæ˜¯è®¡ç®—é¢˜ï¼Œåˆ†æè®¡ç®—æ­¥éª¤]
[æ¯ä¸ªé€‰é¡¹çš„åˆ†æéå¿…è¦ä¸å¾—è¶…è¿‡100å­—]

æ³¨æ„ï¼š
- ä¿æŒæ¨ç†è¿‡ç¨‹å°½é‡ç²¾ç®€
- åªä¿ç•™å¿…è¦çš„æ¨ç†å’Œè®¡ç®—æ­¥éª¤
- æ¨ç†è¿‡ç¨‹æ¸…æ™°å®Œæ•´ï¼Œä¸å¾—ç¼ºå°‘ä¸­é—´æ­¥éª¤
"""
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",  # DeepSeek-Chatæ¨¡å‹
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                timeout=900  # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º900ç§’
            )
            
            content = response.choices[0].message.content
            return content
            
        except Exception as e:
            print(f"è°ƒç”¨DeepSeek-Chat APIå¤±è´¥: {e}")
            return ""  # å¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²

class FinancialDataProcessor:
    def __init__(self, api_key: str, max_workers: int = 5):
        self.api_processor = DeepSeekAPIProcessor(api_key)
        self.processed_count = 0
        self.total_count = 0
        self.answers_list = []  # æ·»åŠ ç­”æ¡ˆåˆ—è¡¨å±æ€§
        self.max_workers = max_workers  # å¹¶å‘çº¿ç¨‹æ•°
        self.lock = threading.Lock()  # çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤å…±äº«å˜é‡
        self.results = []  # å­˜å‚¨ç»“æœçš„çº¿ç¨‹å®‰å…¨åˆ—è¡¨
    
    def _parse_answer_file(self, answer_file: str) -> List[str]:
        """è§£æç­”æ¡ˆæ–‡ä»¶ï¼Œå°†åˆ†ç»„æ ¼å¼è½¬æ¢ä¸ºæŒ‰ç´¢å¼•è®¿é—®çš„ç­”æ¡ˆåˆ—è¡¨"""
        answers = []
        
        with open(answer_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if ':' in line:
                    # åˆ†å‰²èŒƒå›´å’Œç­”æ¡ˆéƒ¨åˆ†
                    range_part, answers_part = line.split(':', 1)
                    # æå–ç­”æ¡ˆï¼Œå»é™¤ç©ºæ ¼
                    line_answers = [ans.strip() for ans in answers_part.split(',')]
                    answers.extend(line_answers)
        
        return answers
    
    def _process_single_question(self, i: int, question_row, answer: str) -> Dict:
        """å¤„ç†å•ä¸ªé—®é¢˜çš„å‡½æ•°ï¼Œç”¨äºå¹¶å‘æ‰§è¡Œ"""
        try:
            question_id = question_row.iloc[0] if len(question_row) > 0 else i
            
            # è·å–å®Œæ•´é—®é¢˜æ–‡æœ¬
            if len(question_row) > 2:
                question = str(question_row.iloc[2])  # ç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            else:
                question = str(question_row.iloc[-1])  # å¦‚æœæ²¡æœ‰ç¬¬ä¸‰åˆ—ï¼Œä½¿ç”¨æœ€åä¸€åˆ—
            
            print(f"\nå¤„ç†é—®é¢˜ {i+1}: ID={question_id}")
            print(f"ç­”æ¡ˆ: {answer}")
            
            # è°ƒç”¨DeepSeek-Chatè¡¥å……è§£é¢˜è¿‡ç¨‹
            print(f"çº¿ç¨‹ {threading.current_thread().name} è°ƒç”¨DeepSeek-Chat...")
            analysis_content = self.api_processor.call_deepseek_chat_for_analysis(question, answer)
            
            if not analysis_content:
                print(f"é—®é¢˜ {i+1} DeepSeek-Chatè°ƒç”¨å¤±è´¥")
                return None
            
            # è§£æåˆ†æå†…å®¹
            problem_analysis, option_analysis, solution_process = self._parse_analysis_content(analysis_content)
            
            # å‡†å¤‡ç»“æœæ•°æ®
            result = {
                'index': i,
                'question_id': question_id,
                'question': question,
                'answer': answer,
                'problem_analysis': problem_analysis,
                'option_analysis': option_analysis,
                'solution_process': solution_process,
                'analysis_content': analysis_content,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°è®¡æ•°å™¨
            with self.lock:
                self.processed_count += 1
                print(f"âœ“ é—®é¢˜ {i+1} å¤„ç†å®Œæˆ (å·²å®Œæˆ: {self.processed_count})")
            
            # APIè°ƒç”¨é—´éš”ï¼ˆé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚ï¼‰
            time.sleep(1)
            
            return result
            
        except Exception as e:
            print(f"å¤„ç†é—®é¢˜ {i+1} æ—¶å‡ºé”™: {e}")
            return None
    
    def process_csv_data_with_answers(self, csv_file: str, answer_file: str, output_excel: str, output_json: str, 
                    start_index: int = 0, end_index: int = None, batch_size: int = 10):
        """å¤„ç†CSVæ•°æ®çš„ä¸»å‡½æ•°ï¼Œä½¿ç”¨å¹¶å‘å¤„ç†
        
        Args:
            csv_file: é—®é¢˜CSVæ–‡ä»¶è·¯å¾„
            answer_file: ç­”æ¡ˆæ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒtxtæ ¼å¼ï¼‰
            output_excel: Excelè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_json: JSONè¾“å‡ºæ–‡ä»¶è·¯å¾„
            start_index: å¼€å§‹å¤„ç†çš„é—®é¢˜ç´¢å¼•ï¼ˆé»˜è®¤0ï¼‰
            end_index: ç»“æŸå¤„ç†çš„é—®é¢˜ç´¢å¼•ï¼ˆé»˜è®¤Noneï¼Œå¤„ç†åˆ°æ–‡ä»¶æœ«å°¾ï¼‰
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆå½“end_indexä¸ºNoneæ—¶ä½¿ç”¨ï¼‰
        """
        print(f"å¼€å§‹å¹¶å‘å¤„ç†CSVæ–‡ä»¶: {csv_file}")
        print(f"ç­”æ¡ˆæ–‡ä»¶: {answer_file}")
        print(f"å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
        
        # è¯»å–é—®é¢˜CSVæ–‡ä»¶ - ä¿®å¤ï¼šæ·»åŠ header=Noneå‚æ•°
        df_questions = pd.read_csv(csv_file, sep='\t', header=None)
        
        # è§£æç­”æ¡ˆæ–‡ä»¶
        self.answers_list = self._parse_answer_file(answer_file)
        print(f"æˆåŠŸè§£æ {len(self.answers_list)} ä¸ªç­”æ¡ˆ")
        
        self.total_count = len(df_questions)
        
        # ç¡®å®šå®é™…çš„ç»“æŸç´¢å¼•
        if end_index is None:
            actual_end_index = min(start_index + batch_size, self.total_count)
            print(f"æ€»å…±{self.total_count}ä¸ªé—®é¢˜ï¼Œå¤„ç†ç¬¬{start_index+1}åˆ°ç¬¬{actual_end_index}ä¸ªé—®é¢˜")
        else:
            actual_end_index = min(end_index, self.total_count)
            print(f"æ€»å…±{self.total_count}ä¸ªé—®é¢˜ï¼Œå¤„ç†ç¬¬{start_index+1}åˆ°ç¬¬{actual_end_index}ä¸ªé—®é¢˜")
        
        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for i in range(start_index, actual_end_index):
            if i < len(self.answers_list):
                question_row = df_questions.iloc[i]
                answer = self.answers_list[i]
                tasks.append((i, question_row, answer))
            else:
                print(f"è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°é—®é¢˜ {i+1} å¯¹åº”çš„ç­”æ¡ˆï¼Œè·³è¿‡")
        
        print(f"å‡†å¤‡å¹¶å‘å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        self.results = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self._process_single_question, i, question_row, answer): (i, question_row, answer)
                for i, question_row, answer in tasks
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_task):
                result = future.result()
                if result is not None:
                    self.results.append(result)
        
        # æŒ‰ç´¢å¼•æ’åºç»“æœ
        self.results.sort(key=lambda x: x['index'])
        
        # ä¿å­˜ç»“æœåˆ°Excelå’ŒJSON
        self._save_results_to_files(output_excel, output_json)
        
        print(f"\nå¹¶å‘å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {self.processed_count} ä¸ªé—®é¢˜")
        
        return [{
            "question": result['question'],
            "answer": result['answer'],
            "problem_analysis": result['problem_analysis'],
            "option_analysis": result['option_analysis'],
            "solution_process": result['solution_process'],
            "full_analysis": result['analysis_content']
        } for result in self.results]
    
    def _save_results_to_files(self, output_excel: str, output_json: str):
        """ä¿å­˜ç»“æœåˆ°Excelå’ŒJSONæ–‡ä»¶"""
        # ä¿å­˜åˆ°Excel
        wb = Workbook()
        ws = wb.active
        ws.title = "è§£é¢˜è¿‡ç¨‹åˆ†æç»“æœ"
        ws.append(["é—®é¢˜ID", "åŸé—®é¢˜", "æ­£ç¡®ç­”æ¡ˆ", "é—®é¢˜åˆ†æ", "é€‰é¡¹åˆ†æ", "è§£é¢˜è¿‡ç¨‹", "å®Œæ•´åˆ†æå†…å®¹", "å¤„ç†æ—¶é—´"])
        
        for result in self.results:
            # æ¸…ç†å®Œæ•´åˆ†æå†…å®¹ä¸­çš„ ### ç¬¦å·
            cleaned_analysis = re.sub(r'###\s*', '', result['analysis_content'])
            
            ws.append([
                result['question_id'],
                result['question'],
                result['answer'],
                result['problem_analysis'],
                result['option_analysis'],
                result['solution_process'],
                cleaned_analysis,  # ä½¿ç”¨æ¸…ç†åçš„å†…å®¹
                result['timestamp']
            ])
        
        wb.save(output_excel)
        print(f"Excelç»“æœå·²ä¿å­˜åˆ°: {output_excel}")
        
        # ä¿å­˜åˆ°JSON
        json_data = [{
            "question": result['question'],
            "answer": result['answer'],
            "problem_analysis": result['problem_analysis'],
            "option_analysis": result['option_analysis'],
            "solution_process": result['solution_process'],
            "full_analysis": re.sub(r'###\s*', '', result['analysis_content'])  # æ¸…ç†åçš„å†…å®¹
        } for result in self.results]
        
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        print(f"JSONæ•°æ®å·²ä¿å­˜åˆ°: {output_json}")
    
    def _parse_analysis_content(self, content: str) -> Tuple[str, str, str]:
        """è§£æåˆ†æå†…å®¹ï¼Œåˆ†ç¦»é—®é¢˜åˆ†æã€é€‰é¡¹åˆ†æå’Œè§£é¢˜è¿‡ç¨‹"""
        problem_analysis = ""
        option_analysis = ""
        solution_process = ""
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†ç¦»ä¸åŒéƒ¨åˆ†
        problem_pattern = r'é—®é¢˜åˆ†æ[ï¼š:]\s*([\s\S]*?)(?=é€‰é¡¹åˆ†æ|è§£é¢˜è¿‡ç¨‹|$)'
        option_pattern = r'é€‰é¡¹åˆ†æ[ï¼š:]\s*([\s\S]*?)(?=è§£é¢˜è¿‡ç¨‹|$)'
        solution_pattern = r'è§£é¢˜è¿‡ç¨‹[ï¼š:]\s*([\s\S]*?)$'
        
        problem_match = re.search(problem_pattern, content)
        if problem_match:
            problem_analysis = problem_match.group(1).strip()
        
        option_match = re.search(option_pattern, content)
        if option_match:
            option_analysis = option_match.group(1).strip()
        
        solution_match = re.search(solution_pattern, content)
        if solution_match:
            solution_process = solution_match.group(1).strip()
        
        return problem_analysis, option_analysis, solution_process

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # é…ç½®APIå¯†é’¥
    API_KEY = "none"  # ğŸ”§ è¯·æ›¿æ¢ä¸ºæ‚¨çš„APIå¯†é’¥
    
    # æ–‡ä»¶è·¯å¾„
    CSV_FILE = "input.csv"
    ANSWER_FILE = "final_result_txt.txt"
    EXCEL_OUTPUT = "answer_results.xlsx"
    JSON_OUTPUT = "answer_data.json"
    
    # åˆ›å»ºå¤„ç†å™¨ï¼ˆè®¾ç½®å¹¶å‘çº¿ç¨‹æ•°ä¸º5ï¼‰
    processor = FinancialDataProcessor(API_KEY, max_workers=5)
    
    # å¤„ç†æ•°æ®
    processor.process_csv_data_with_answers(
        csv_file=CSV_FILE,
        answer_file=ANSWER_FILE,
        output_excel=EXCEL_OUTPUT,
        output_json=JSON_OUTPUT,
        start_index=0,
        end_index= 100
    )

if __name__ == "__main__":
    main()